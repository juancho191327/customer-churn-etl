# Telco Customer Churn - ETL Project

Este proyecto implementa un pipeline ETL (Extract, Transform, Load) para analizar la tasa de abandono de clientes (churn) en un proveedor de telecomunicaciones. Se descarga un dataset desde Kaggle, se realiza una limpieza y transformaciÃ³n de los datos, y finalmente se carga en una base de datos MySQL.

## ğŸš€ Requisitos

Antes de ejecutar el proyecto, asegÃºrate de tener instalados los siguientes requisitos:

- Python 3.12
- Poetry (para la gestiÃ³n de dependencias)
- MySQL Server
- Una cuenta en Kaggle
- Apache Airflow
- Java 17 o superior para Metabase

## ğŸ“‚ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el repositorio
```bash
git clone https://github.com/juancho191327/customer-churn-etl.git
cd customer-churn-etl
```

### 2ï¸âƒ£ Configurar un entorno virtual con Poetry
```bash
poetry install
```

### 3ï¸âƒ£ Configurar credenciales de Kaggle

Para descargar el dataset, es necesario obtener las credenciales de Kaggle:

1. Accede a [Kaggle](https://www.kaggle.com/) y dirÃ­gete a *Account*.
2. DesplÃ¡zate hasta la secciÃ³n *API* y haz clic en *Create New API Token*.
3. Se descargarÃ¡ un archivo `kaggle.json`. Mueve este archivo a la carpeta `~/.kaggle/` (en Windows, `C:\Users\tu-usuario\.kaggle\`).

Ejemplo de comando en Linux/Mac:
```bash
mkdir -p ~/.kaggle
mv /ruta/al/archivo/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json  # Asegurar permisos adecuados
```

### 4ï¸âƒ£ Configurar credenciales de MySQL

Crea un archivo `.env` en la raÃ­z del proyecto con la siguiente estructura:
```ini
DB_HOST=localhost
DB_USER=tu_usuario
DB_PASSWORD=tu_contraseÃ±a
DB_NAME=customer_churn
```

## ğŸ› ï¸ EjecuciÃ³n del ETL

Para ejecutar el pipeline ETL, simplemente corre el siguiente comando:
```bash
poetry run python main.py
```

## â³ AutomatizaciÃ³n con Apache Airflow

El pipeline ETL estÃ¡ automatizado mediante Apache Airflow. Para ejecutarlo:

1. Inicia Airflow:
```bash
airflow standalone
```
2. Accede a la interfaz en `http://localhost:8080` con:
   - Usuario: `admin`
   - ContraseÃ±a: `admin`
3. Activa y ejecuta el DAG `etl_telco_churn`.

## ğŸ“Š VisualizaciÃ³n en Metabase

El anÃ¡lisis de datos se presenta en un dashboard en **Metabase**.

### 1ï¸âƒ£ Iniciar Metabase
```bash
java -jar metabase.jar
```
Accede a `http://localhost:3000`, configura la conexiÃ³n a MySQL y carga el dashboard.

## ğŸ“Œ Notas Adicionales
- AsegÃºrate de que MySQL estÃ© corriendo antes de ejecutar el pipeline.
- Si necesitas limpiar la base de datos y reiniciar la carga, puedes eliminar la tabla con:
```sql
DROP TABLE customer_churn_extract;
```

## ğŸ“ Contacto
Si tienes preguntas o mejoras, no dudes en contribuir o abrir un issue en el repositorio. ğŸš€
